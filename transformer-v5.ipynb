{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce61c533-2231-4f2c-8f4a-d5fd077f9905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import glob\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Literal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import cbor2\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "RUN_KEY = \"attention-v5\"\n",
    "summary = SummaryWriter(f\"runs/{RUN_KEY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c272b853-a3f5-4a8f-9aaf-e2f026a04339",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e88efede-b487-49c3-969f-af286715054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    context_len: int = 512\n",
    "    n_layers: int = 12\n",
    "    n_heads: int = 8\n",
    "    n_embeds: int = 32\n",
    "    n_tokens: int = 128\n",
    "    n_added_params: int = 3\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True\n",
    "    @property\n",
    "    def n_embed_and_added(self):\n",
    "        return self.n_embeds + self.n_added_params\n",
    "    @property\n",
    "    def n_tokens_and_added(self):\n",
    "        return self.n_tokens + self.n_added_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aff63cf-a906-4e18-b939-4302c6a44242",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_paths = glob.glob('moonlight.tokens')\n",
    "#display(track_paths)\n",
    "tracks = []\n",
    "for path in track_paths:\n",
    "    with open(path, 'rb') as f:\n",
    "        track_data = cbor2.load(f)\n",
    "        if len(track_data) < 100:\n",
    "            print(\"too short:\", path)\n",
    "        tracks.append([x for x in track_data if x[1] > 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2d10b79-a6f0-43e9-9675-2b85c7cd9afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37, 2.6666666666666665, 0.0, 0.29133858267716534], [49, 3.3333333333333335, 0.0, 0.2283464566929134], [56, 0.3333333333333333, 0.0, 0.36220472440944884], [61, 0.3333333333333333, 0.3333333333333333, 0.23622047244094488], [64, 0.6666666666666666, 0.3333333333333333, 0.33858267716535434]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(tracks[0][0:5])\n",
    "print(len(tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "049fe1ac-2fda-4709-8948-88139476e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor([event for track in tracks for event in track])\n",
    "split_n = int(0.9 * len(data))\n",
    "train_data = data[:split_n]\n",
    "eval_data = data[split_n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7f9cae-8dda-42b4-9bec-451f26b381ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split: Literal['train', 'eval'], config: ModelConfig, batch_size=BATCH_SIZE):\n",
    "    data = train_data if split == 'train' else eval_data\n",
    "    ix = torch.randint(len(data) - config.context_len, (batch_size,))\n",
    "    x = torch.stack([data[i:i+config.context_len] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+config.context_len+1] for i in ix])\n",
    "    return x.cuda(), y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07a08b27-4403-4603-b45c-9275af874383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch('train', ModelConfig())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d97a66e-bdd2-4567-8bf9-31a37b88e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        assert config.n_embeds % config.n_heads == 0\n",
    "        self.config = config\n",
    "        head_size = config.n_embeds // config.n_heads\n",
    "        self.key = nn.Linear(config.n_embeds, head_size, bias=config.bias)\n",
    "        self.query = nn.Linear(config.n_embeds, head_size, bias=config.bias)\n",
    "        self.value = nn.Linear(config.n_embeds, head_size, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(config.context_len, config.context_len)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        w = q @ k.transpose(-2, -1) * C**-0.5\n",
    "        w = w.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        w = F.softmax(w, dim=-1)\n",
    "        w = self.dropout(w)\n",
    "        v = self.value(x)\n",
    "        out = w @ v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        head_size = config.n_embeds // config.n_heads\n",
    "        self.heads = nn.ModuleList([SelfAttention(config) for _ in range(config.n_heads)])\n",
    "        self.projection = nn.Linear(config.n_heads * head_size, config.n_embeds, bias=False)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.projection(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(config.n_embeds, 4 * config.n_embeds),\n",
    "            nn.ReLU(), # TODO: GELU\n",
    "            nn.Linear(4 * config.n_embeds, config.n_embeds),\n",
    "            nn.Dropout(config.dropout),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class SABlock(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        head_size = config.n_embeds // config.n_heads\n",
    "        self.sa = MultiHeadAttention(config)\n",
    "        self.ffwd = FeedForward(config)\n",
    "        self.ln1 = nn.LayerNorm(config.n_embeds)\n",
    "        self.ln2 = nn.LayerNorm(config.n_embeds)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4823ed7d-46c4-4d71-88a9-e8400508dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.token_embedding_table = nn.Embedding(config.n_tokens, config.n_embeds)\n",
    "        self.position_embedding_table = nn.Embedding(config.context_len, config.n_embeds)\n",
    "        self.drop = nn.Dropout(config.dropout)\n",
    "        self.blocks = nn.Sequential(*[SABlock(config) for _ in range(config.n_layers)])\n",
    "        self.layer_norm = nn.LayerNorm(config.n_embed_and_added, bias=config.bias)\n",
    "        self.lm_head = nn.Linear(config.n_embed_and_added, config.n_tokens_and_added, bias=False)\n",
    "        # Tie weights\n",
    "        print(f\"{self.token_embedding_table.weight.shape=}\")\n",
    "        print(f\"{self.lm_head.weight.shape=}\")\n",
    "        tie_weights = torch.nn.Parameter(self.lm_head.weight[:config.n_tokens, :config.n_embeds])\n",
    "        print(f\"{tie_weights.shape=}\")\n",
    "        self.token_embedding_table.weight = tie_weights\n",
    "        self.apply(self._init_weights)\n",
    "        # We scale the weights of residual layers at initialization by a factor of 1/âˆšN\n",
    "        # where N is the number of residual layers.\n",
    "        # Language Models are Unsupervised Multitask Learners\n",
    "        for name, p in self.named_parameters():\n",
    "            if name.endswith('projection.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layers)) \n",
    "                \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "    def forward(self, x, targets=None):\n",
    "        device = x.device\n",
    "        B, T, C = x.shape\n",
    "        assert T <= self.config.context_len, T\n",
    "        tokens = x[:,:,0].long()\n",
    "        added = x[:,:,1:].view(-1, self.config.context_len, self.config.n_added_params)\n",
    "        tok_emb = self.token_embedding_table(tokens)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, dtype=torch.long, device=device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.drop(x)\n",
    "        x = self.blocks(x)\n",
    "        x = torch.cat((x, added), dim=2)\n",
    "        x = self.layer_norm(x)\n",
    "        if targets is None:\n",
    "            # only use last position for generation\n",
    "            logits = self.lm_head(x[:, [-1], :])\n",
    "            return logits, None, None, None\n",
    "        logits = self.lm_head(x)\n",
    "        B, T, C = logits.shape\n",
    "        classes = targets[:, :, 0].long()\n",
    "        added_params = targets[:, :, 1:]\n",
    "        label_loss = F.cross_entropy(logits.view(B*T, C), classes.view(B*T))\n",
    "        sq_err = ((added_params[:, :, -self.config.n_added_params:] - logits[:, :, -self.config.n_added_params:]) ** 2)\n",
    "        added_param_loss = sq_err.mean(dim=1).mean(dim=0).sum()\n",
    "        loss = label_loss + added_param_loss\n",
    "        return logits, loss, label_loss, added_param_loss\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        model.eval()\n",
    "        out = []\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx = idx[:, -self.config.context_len:] # truncate context\n",
    "            logits, _, _, _ = self(idx)\n",
    "            # TODO: temperature and top-k\n",
    "            probs = F.softmax(logits[:, -1, :self.config.n_tokens], dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1) # B, 1\n",
    "            token = next_token.int().item()\n",
    "            added_params = logits[:,-1,-self.config.n_added_params:].view(1, self.config.n_added_params)\n",
    "            next_idx = torch.cat((next_token, added_params), dim=-1) # B, 3\n",
    "            out.append([token] + added_params.tolist()[0])\n",
    "            idx = torch.cat((idx, next_idx.view(1, -1, 1 + self.config.n_added_params)), dim=1)\n",
    "            if next_token.item() == 3:\n",
    "                break\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0ab234d-c40b-4ce0-9189-2c7203567978",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelStats:\n",
    "    def __init__(self, model: Model):\n",
    "        self.model = model\n",
    "\n",
    "    def estimate_flops(self):\n",
    "        pass\n",
    "        \n",
    "    def num_parameters(self):\n",
    "        n_elements = sum(p.numel() for p in self.model.parameters())\n",
    "        return n_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59797891-dff7-4de0-932c-2771dffae70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.token_embedding_table.weight.shape=torch.Size([128, 32])\n",
      "self.lm_head.weight.shape=torch.Size([131, 35])\n",
      "tie_weights.shape=torch.Size([128, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_292730/2605964146.py:36: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert T <= self.config.context_len, T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "177199"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = ModelConfig()\n",
    "model = Model(config).cuda()\n",
    "summary.add_graph(model, get_batch('train', config))\n",
    "global_training_steps = 0\n",
    "stats = ModelStats(model)\n",
    "display(stats.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41e8b53b-5dda-46c3-a421-2de783e5c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16\n",
    "autocast_ctx = torch.autocast(device_type='cuda', dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1d872ba-d518-407e-b379-1ab1ca4b4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_iters = 100\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train']:#, 'eval']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split, config)\n",
    "            with autocast_ctx:\n",
    "                logits, loss, _, _ = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d6d4462-6ab6-4845-a04b-e75469c623cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': tensor(7.1638)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad5e7acd-d020-4e22-b3cd-5189603fdb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 100000: 7.1725, lr=[0.001]\n",
      "    100/ 100000: 4.3534, lr=[0.001]\n",
      "    200/ 100000: 3.4749, lr=[0.001]\n",
      "    300/ 100000: 2.3091, lr=[0.001]\n",
      "    400/ 100000: 1.4322, lr=[0.001]\n",
      "    500/ 100000: 0.8878, lr=[0.0002]\n",
      "    600/ 100000: 0.6025, lr=[0.0002]\n",
      "    700/ 100000: 0.5173, lr=[0.0002]\n",
      "    800/ 100000: 0.4074, lr=[0.0002]\n",
      "    900/ 100000: 0.3618, lr=[0.0002]\n",
      "   1000/ 100000: 0.2988, lr=[4e-05]\n",
      "   1100/ 100000: 0.2709, lr=[4e-05]\n",
      "   1200/ 100000: 0.2565, lr=[4e-05]\n",
      "   1300/ 100000: 0.2493, lr=[4e-05]\n",
      "   1400/ 100000: 0.2341, lr=[4e-05]\n",
      "   1500/ 100000: 0.2287, lr=[8.000000000000001e-06]\n",
      "   1600/ 100000: 0.2181, lr=[8.000000000000001e-06]\n",
      "   1700/ 100000: 0.2145, lr=[8.000000000000001e-06]\n",
      "   1800/ 100000: 0.2233, lr=[8.000000000000001e-06]\n",
      "   1900/ 100000: 0.2222, lr=[8.000000000000001e-06]\n",
      "   2000/ 100000: 0.2156, lr=[1.6000000000000004e-06]\n",
      "   2100/ 100000: 0.2089, lr=[1.6000000000000004e-06]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_ctx:\n\u001b[1;32m---> 13\u001b[0m     logits, loss, label_loss, added_param_loss \u001b[38;5;241m=\u001b[39m \u001b[40mmodel\u001b[49m\u001b[40m(\u001b[49m\u001b[40mXb\u001b[49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[40mYb\u001b[49m\u001b[40m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     15\u001b[0m     summary\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem(), global_training_steps)\n",
      "File \u001b[1;32m~/src/midi-tokenizer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;40mself\u001b[39;49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40m_call_impl\u001b[49m\u001b[40m(\u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40margs\u001b[49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40mkwargs\u001b[49m\u001b[40m)\u001b[49m\n",
      "File \u001b[1;32m~/src/midi-tokenizer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[40mforward_call\u001b[49m\u001b[40m(\u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40margs\u001b[49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40mkwargs\u001b[49m\u001b[40m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 43\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, x, targets)\u001b[0m\n\u001b[0;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m tok_emb \u001b[38;5;241m+\u001b[39m pos_emb\n\u001b[0;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(x)\n\u001b[1;32m---> 43\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;40mself\u001b[39;49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40mblocks\u001b[49m\u001b[40m(\u001b[49m\u001b[40mx\u001b[49m\u001b[40m)\u001b[49m\n\u001b[0;32m     44\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, added), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     45\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(x)\n",
      "File \u001b[1;32m~/src/midi-tokenizer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;40mself\u001b[39;49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40m_call_impl\u001b[49m\u001b[40m(\u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40margs\u001b[49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40mkwargs\u001b[49m\u001b[40m)\u001b[49m\n",
      "File \u001b[1;32m~/src/midi-tokenizer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[40mforward_call\u001b[49m\u001b[40m(\u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40margs\u001b[49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40mkwargs\u001b[49m\u001b[40m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~/src/midi-tokenizer/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[40mmodule\u001b[49m\u001b[40m(\u001b[49m\u001b[38;5;28;40minput\u001b[39;49m\u001b[40m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~/src/midi-tokenizer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;40mself\u001b[39;49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40m_call_impl\u001b[49m\u001b[40m(\u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40margs\u001b[49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40mkwargs\u001b[49m\u001b[40m)\u001b[49m\n",
      "File \u001b[1;32m~/src/midi-tokenizer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[40mforward_call\u001b[49m\u001b[40m(\u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40margs\u001b[49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40mkwargs\u001b[49m\u001b[40m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 62\u001b[0m, in \u001b[0;36mSABlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 62\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;40mself\u001b[39;49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40msa\u001b[49m\u001b[40m(\u001b[49m\u001b[38;5;28;40mself\u001b[39;49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40mln1\u001b[49m\u001b[40m(\u001b[49m\u001b[40mx\u001b[49m\u001b[40m)\u001b[49m\u001b[40m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffwd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(x))\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~/src/midi-tokenizer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;40mself\u001b[39;49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40m_call_impl\u001b[49m\u001b[40m(\u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40margs\u001b[49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40mkwargs\u001b[49m\u001b[40m)\u001b[49m\n",
      "File \u001b[1;32m~/src/midi-tokenizer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[40mforward_call\u001b[49m\u001b[40m(\u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40margs\u001b[49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40mkwargs\u001b[49m\u001b[40m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 34\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 34\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\u001b[40m[\u001b[49m\u001b[40mh\u001b[49m\u001b[40m(\u001b[49m\u001b[40mx\u001b[49m\u001b[40m)\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;28;40;01mfor\u001b[39;49;00m\u001b[40m \u001b[49m\u001b[40mh\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;129;40;01min\u001b[39;49;00m\u001b[40m \u001b[49m\u001b[38;5;28;40mself\u001b[39;49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40mheads\u001b[49m\u001b[40m]\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     35\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojection(out)\n\u001b[0;32m     36\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(out)\n",
      "Cell \u001b[1;32mIn[9], line 34\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 34\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[40mh\u001b[49m\u001b[40m(\u001b[49m\u001b[40mx\u001b[49m\u001b[40m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     35\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojection(out)\n\u001b[0;32m     36\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(out)\n",
      "File \u001b[1;32m~/src/midi-tokenizer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;40mself\u001b[39;49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40m_call_impl\u001b[49m\u001b[40m(\u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40margs\u001b[49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40mkwargs\u001b[49m\u001b[40m)\u001b[49m\n",
      "File \u001b[1;32m~/src/midi-tokenizer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[40mforward_call\u001b[49m\u001b[40m(\u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40margs\u001b[49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40mkwargs\u001b[49m\u001b[40m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 18\u001b[0m, in \u001b[0;36mSelfAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery(x)\n\u001b[0;32m     17\u001b[0m w \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m C\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m---> 18\u001b[0m w \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mmasked_fill(\u001b[38;5;28;40mself\u001b[39;49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40mtril\u001b[49m[:T, :T] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     19\u001b[0m w \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(w, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(w)\n",
      "File \u001b[1;32m~/src/midi-tokenizer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1682\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1673\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m   1675\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[0;32m   1676\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1680\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[1;32m-> 1682\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1683\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m   1684\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lossi = []\n",
    "model.train()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.2)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "max_steps = 100_000\n",
    "\n",
    "for i in range(max_steps+1):\n",
    "    global_training_steps += 1\n",
    "    Xb, Yb = get_batch('train', config)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    with autocast_ctx:\n",
    "        logits, loss, label_loss, added_param_loss = model(Xb, Yb)\n",
    "    if i % 10 == 0:\n",
    "        summary.add_scalar('loss', loss.item(), global_training_steps)\n",
    "        summary.add_scalar('label_loss', label_loss.item(), global_training_steps)\n",
    "        summary.add_scalar('added_param_loss', added_param_loss.item(), global_training_steps)\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    # track\n",
    "    scheduler.step()\n",
    "    if i % 100 == 0:\n",
    "        print(f\"{i:7d}/{max_steps:7d}: {loss.item():.4f}, lr={scheduler.get_last_lr()}\")\n",
    "    lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36f1bbef-28fb-4770-871d-e89eb09e9ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efc44997690>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "# instead, average across 1_000 points\n",
    "r = (len(lossi) // 100) * 100\n",
    "plt.plot(torch.tensor(lossi)[:r].view(-1, 100).mean(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc6531a8-93c7-4044-9415-30a04ee4f954",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 512, 3]' is invalid for input of size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      2\u001b[0m     gen_ctx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m]] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m [[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m]]], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     generated \u001b[38;5;241m=\u001b[39m \u001b[40mmodel\u001b[49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40mgenerate\u001b[49m\u001b[40m(\u001b[49m\u001b[40mgen_ctx\u001b[49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[40mmax_new_tokens\u001b[49m\u001b[38;5;241;40m=\u001b[39;49m\u001b[38;5;241;40m1_000\u001b[39;49m\u001b[40m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m         cbor2\u001b[38;5;241m.\u001b[39mdump(generated, f)\n",
      "File \u001b[1;32m~/src/midi-tokenizer/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[40mfunc\u001b[49m\u001b[40m(\u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40margs\u001b[49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40mkwargs\u001b[49m\u001b[40m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 66\u001b[0m, in \u001b[0;36mModel.generate\u001b[1;34m(self, idx, max_new_tokens, temperature, top_k)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_new_tokens):\n\u001b[0;32m     65\u001b[0m     idx \u001b[38;5;241m=\u001b[39m idx[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_len:] \u001b[38;5;66;03m# truncate context\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     logits, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;40mself\u001b[39;49m\u001b[40m(\u001b[49m\u001b[40midx\u001b[49m\u001b[40m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# TODO: temperature and top-k\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mn_tokens], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~/src/midi-tokenizer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;40mself\u001b[39;49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40m_call_impl\u001b[49m\u001b[40m(\u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40margs\u001b[49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40mkwargs\u001b[49m\u001b[40m)\u001b[49m\n",
      "File \u001b[1;32m~/src/midi-tokenizer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[40mforward_call\u001b[49m\u001b[40m(\u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40margs\u001b[49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[38;5;241;40m*\u001b[39;49m\u001b[40mkwargs\u001b[49m\u001b[40m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 38\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, x, targets)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m T \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_len, T\n\u001b[0;32m     37\u001b[0m tokens \u001b[38;5;241m=\u001b[39m x[:,:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m---> 38\u001b[0m added \u001b[38;5;241m=\u001b[39m \u001b[40mx\u001b[49m\u001b[40m[\u001b[49m\u001b[40m:\u001b[49m\u001b[40m,\u001b[49m\u001b[40m:\u001b[49m\u001b[40m,\u001b[49m\u001b[38;5;241;40m1\u001b[39;49m\u001b[40m:\u001b[49m\u001b[40m]\u001b[49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40mview\u001b[49m\u001b[40m(\u001b[49m\u001b[38;5;241;40m-\u001b[39;49m\u001b[38;5;241;40m1\u001b[39;49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;28;40mself\u001b[39;49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40mconfig\u001b[49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40mcontext_len\u001b[49m\u001b[40m,\u001b[49m\u001b[40m \u001b[49m\u001b[38;5;28;40mself\u001b[39;49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40mconfig\u001b[49m\u001b[38;5;241;40m.\u001b[39;49m\u001b[40mn_added_params\u001b[49m\u001b[40m)\u001b[49m\n\u001b[0;32m     39\u001b[0m tok_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding_table(tokens)\n\u001b[0;32m     40\u001b[0m pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table(torch\u001b[38;5;241m.\u001b[39marange(T, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[-1, 512, 3]' is invalid for input of size 6"
     ]
    }
   ],
   "source": [
    "for sample in range(1):\n",
    "    gen_ctx = torch.tensor([[[1, 0.0, 0.0, 0.0]] * (config.context_len - 1) + [[2, 0.0, 0.0, 0.0]]], device='cuda')\n",
    "    generated = model.generate(gen_ctx, max_new_tokens=1_000)\n",
    "    with open(f\"sample-{sample}.tokens\", 'wb') as f:\n",
    "        cbor2.dump(generated, f)\n",
    "        print(\"wrote\", f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e955a731-5552-4b8c-a1be-5b7c3e33047a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[44, 5.128375053405762, 0.2053591012954712, 0.312602162361145],\n",
       " [48, 1.2680975198745728, 0.16892729699611664, 0.30966809391975403],\n",
       " [52, 0.1487143337726593, 0.4600341320037842, 0.44265007972717285],\n",
       " [44, 3.559011936187744, 0.19095751643180847, 0.2573602795600891],\n",
       " [48, 1.131675362586975, 0.19380924105644226, 0.31454986333847046],\n",
       " [51, 0.09191866219043732, 0.4648793637752533, 0.4293871521949768],\n",
       " [63, -0.19657158851623535, 0.8193220496177673, 0.47589045763015747],\n",
       " [44, 5.699105262756348, 0.4226289987564087, 0.31427955627441406],\n",
       " [60, 1.3957886695861816, 0.1819189190864563, 0.2973012924194336],\n",
       " [60, 0.4579460024833679, 0.498224139213562, 0.4220420718193054],\n",
       " [60, -0.05084109306335449, 0.6404372453689575, 0.40330371260643005],\n",
       " [60, -0.25005584955215454, 0.6891573667526245, 0.37092331051826477],\n",
       " [60, -0.2855437099933624, 0.7029449939727783, 0.35469958186149597],\n",
       " [60, -0.24737219512462616, 0.7107375860214233, 0.35518765449523926],\n",
       " [60, -0.16425855457782745, 0.7206411361694336, 0.36730054020881653],\n",
       " [60, -0.01650094985961914, 0.7296096086502075, 0.38484179973602295],\n",
       " [63, 0.26402127742767334, 0.7569500207901001, 0.4191909432411194],\n",
       " [44, 3.9081344604492188, 0.2357121706008911, 0.24241721630096436],\n",
       " [48, 1.5445729494094849, 0.18374377489089966, 0.3173239231109619],\n",
       " [51, 0.2584969699382782, 0.40977489948272705, 0.39595821499824524],\n",
       " [60, 0.00686192512512207, 0.8173570036888123, 0.5179677605628967],\n",
       " [32, 5.503998756408691, 0.6178967952728271, 0.33870333433151245],\n",
       " [44, 3.8639917373657227, 0.02730920910835266, 0.2408367395401001],\n",
       " [48, 1.6012210845947266, 0.15813350677490234, 0.3302396535873413],\n",
       " [52, 0.29828059673309326, 0.400837242603302, 0.3911077380180359],\n",
       " [44, 3.292147636413574, 0.14705684781074524, 0.23789536952972412],\n",
       " [48, 1.6194214820861816, 0.18588784337043762, 0.3307066559791565],\n",
       " [51, 0.2716144621372223, 0.40518876910209656, 0.3840729594230652],\n",
       " [56, 0.00765836238861084, 0.8052322268486023, 0.4946368336677551],\n",
       " [44, 4.22715425491333, 0.27004894614219666, 0.28122299909591675],\n",
       " [50, 1.7877389192581177, 0.18749740719795227, 0.3278430700302124],\n",
       " [51, 0.15215030312538147, 0.4903131425380707, 0.389500230550766],\n",
       " [73, -0.06645217537879944, 0.8228328824043274, 0.4756377339363098],\n",
       " [64, -0.49879229068756104, 0.703667402267456, 0.30393683910369873],\n",
       " [68, -0.3697326183319092, 0.7575459480285645, 0.344136118888855],\n",
       " [44, 5.679347991943359, 0.39149874448776245, 0.32955747842788696],\n",
       " [48, 1.7675176858901978, 0.17783334851264954, 0.3138826787471771],\n",
       " [51, 0.3749788701534271, 0.39464277029037476, 0.37639954686164856],\n",
       " [56, 0.07117903232574463, 0.8017807006835938, 0.4961501359939575],\n",
       " [44, 4.08458137512207, 0.25737449526786804, 0.27497225999832153],\n",
       " [48, 1.8225010633468628, 0.19204987585544586, 0.33285287022590637],\n",
       " [51, 0.39847782254219055, 0.3951030969619751, 0.3725060820579529],\n",
       " [56, 0.08427250385284424, 0.796678900718689, 0.4899756908416748],\n",
       " [44, 4.012106418609619, 0.25283685326576233, 0.27097368240356445],\n",
       " [48, 1.8613865375518799, 0.19609446823596954, 0.3335401713848114],\n",
       " [51, 0.41305845975875854, 0.3954038918018341, 0.36782777309417725],\n",
       " [66, 0.09604990482330322, 0.7916377782821655, 0.4837440848350525],\n",
       " [61, -0.26806405186653137, 0.7082313299179077, 0.35315999388694763],\n",
       " [44, 2.9054555892944336, 0.12252813577651978, 0.21048617362976074],\n",
       " [48, 1.786406397819519, 0.20537309348583221, 0.34184539318084717],\n",
       " [51, 0.40801337361335754, 0.4005511999130249, 0.3643312454223633],\n",
       " [54, 0.10611340403556824, 0.7905446290969849, 0.47965776920318604],\n",
       " [60, -0.4949859082698822, 0.7322484850883484, 0.351463258266449],\n",
       " [44, 3.5971767902374268, 0.2864828407764435, 0.22967801988124847],\n",
       " [44, 1.9829225540161133, 0.21132729947566986, 0.3331065773963928],\n",
       " [51, 1.8527522087097168, 0.23768749833106995, 0.3464205265045166],\n",
       " [73, 0.808323860168457, 0.6220868825912476, 0.48584598302841187],\n",
       " [64, -0.18840166926383972, 0.637330174446106, 0.3342265188694],\n",
       " [68, -0.15284357964992523, 0.7513588666915894, 0.3869779407978058],\n",
       " [44, 4.459383010864258, 0.2777365446090698, 0.27504193782806396],\n",
       " [48, 1.8850845098495483, 0.19889812171459198, 0.32947272062301636],\n",
       " [52, 0.5668196082115173, 0.4032518267631531, 0.36081939935684204],\n",
       " [44, 3.2190961837768555, 0.13097047805786133, 0.22741973400115967],\n",
       " [51, 1.9745877981185913, 0.20591264963150024, 0.3414342403411865],\n",
       " [57, 0.8188334703445435, 0.6016933917999268, 0.4702998101711273],\n",
       " [37, -0.06653878092765808, 0.6259372234344482, 0.4113757908344269],\n",
       " [44, 3.3439855575561523, 0.11084020137786865, 0.22785980999469757],\n",
       " [46, 1.999659776687622, 0.2014094740152359, 0.33969029784202576],\n",
       " [44, 2.428734302520752, 0.08278927206993103, 0.27394092082977295],\n",
       " [44, 1.8318449258804321, 0.22374732792377472, 0.34531328082084656],\n",
       " [51, 1.7577853202819824, 0.25826016068458557, 0.3384220004081726],\n",
       " [56, 0.7032971382141113, 0.6338617205619812, 0.4603591561317444],\n",
       " [44, 3.5953896045684814, 0.19243115186691284, 0.25208017230033875],\n",
       " [48, 2.0541634559631348, 0.2142580896615982, 0.332181453704834],\n",
       " [51, 0.43954604864120483, 0.39572674036026, 0.3413209319114685],\n",
       " [68, 0.13554024696350098, 0.7731266617774963, 0.4432860016822815],\n",
       " [44, 4.139739990234375, 0.24782970547676086, 0.2638525068759918],\n",
       " [51, 2.004070520401001, 0.2123524248600006, 0.3244292736053467],\n",
       " [73, 0.8065853118896484, 0.5942574739456177, 0.4468468427658081],\n",
       " [64, -0.2141912281513214, 0.625011146068573, 0.30735284090042114]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(generated[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6661ae5a-db53-495d-93ca-27f63bfb7249",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def split_loss(split):\n",
    "    model.eval()\n",
    "    data = {\n",
    "        \"train\": train_data,\n",
    "        \"eval\": eval_data,\n",
    "    }[split]\n",
    "    ix = torch.randint(len(data) - CONTEXT_LEN, (BATCH_SIZE,))\n",
    "    x = torch.stack([data[i:i+CONTEXT_LEN] for i in ix]).cuda()\n",
    "    y = torch.stack([data[i+1:i+CONTEXT_LEN+1] for i in ix]).cuda()\n",
    "    logits, loss = model(x, y)\n",
    "    print(split, loss.item())\n",
    "    model.train()\n",
    "\n",
    "split_loss(\"train\")\n",
    "split_loss(\"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "80577faf-3600-40d2-8e5a-1a38293716dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a9e3406-855e-43d4-822c-e4b03a0d7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0f043-50af-4818-bc4d-c6071aa6c915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
